{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data stored in temp folder to see how uncertainty data compares to the random\n",
    "    # burst on its own\n",
    "    elif start == '3':\n",
    "        t = Table.read('tempBurstData.txt', format='ascii.ecsv')\n",
    "        \n",
    "    # read in data from table to check least squares fitting\n",
    "    elif start == '4':\n",
    "        makeleastSQ = input('Do you wish to make the table to store least squares data in? (1 for yes): ')\n",
    "        \n",
    "        if makeleastSQ == '1':\n",
    "            colnames = ('Energy', 'Azimuth', 'Zenith', 'hits1', 'hits2', 'hits3', 'hits4')\n",
    "            t = Table(names=colnames)\n",
    "            t.write('leastSQTestData.txt', format='ascii.ecsv')\n",
    "        else:\n",
    "            t = Table.read('leastSQTestData.txt', format='ascii.ecsv')\n",
    "    \n",
    "    elif start == '5':\n",
    "        t = Table.read('leastSQTestData.txt', format='ascii.ecsv')\n",
    "        for i in range(0, len(hitsData)):\n",
    "            t.add_row([LocalizationDict2['Energy'][i], LocalizationDict2['Azimuth'][i],\n",
    "            LocalizationDict2['Zenith'][i], LocalizationDict2['hits1'][i],\n",
    "            LocalizationDict2['hits2'][i], LocalizationDict2['hits3'][i],\n",
    "            LocalizationDict2['hits4'][i]])\n",
    "            t.write('leastSQTestData.txt', format='ascii.ecsv')\n",
    "               \n",
    "# continue to use simple testing approach with user-defined GRB           \n",
    "else:\n",
    "    \n",
    "    # if making table for the first time, use dictionary to import values and col names\n",
    "    if start == '1':\n",
    "        colnames = ('Energy', 'Azimuth', 'Zenith', 'hits1', 'hits2', 'hits3', 'hits4')\n",
    "        t = Table(LocalizationDict2, names=colnames)\n",
    "        t.write('localTable2.txt', format='ascii.ecsv')\n",
    "        \n",
    "    # adding data to table, use dictionary and add new row per simulation    \n",
    "    else:\n",
    "        t = Table.read('localTable2.txt', format='ascii.ecsv')\n",
    "        for i in range(0, len(hitsData)):\n",
    "            t.add_row([LocalizationDict2['Energy'][i], LocalizationDict2['Azimuth'][i],\n",
    "            LocalizationDict2['Zenith'][i], LocalizationDict2['hits1'][i],\n",
    "            LocalizationDict2['hits2'][i], LocalizationDict2['hits3'][i],\n",
    "            LocalizationDict2['hits4'][i]])\n",
    "            t.write('localTable2.txt', format='ascii.ecsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # a = np.array([[1, 2], [3, 4]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data to least squares test data    \n",
    "    elif storeTemp == '2':\n",
    "        tab = Table.read('leastSQTestData.txt', format='ascii.ecsv')\n",
    "        for i in range(0, len(l1)):\n",
    "            tab.add_row([area['keV'][0], uncertAngle[i],\n",
    "            area['ze'][0], resultArray[0][i],\n",
    "            resultArray[1][i], resultArray[2][i],\n",
    "            resultArray[3][i]])\n",
    "            tab.write('leastSQTestData.txt', format='ascii.ecsv')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputDet)\n",
    "# print((np.sum((hitsArray - inputDet)**2, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "else: #for the weird localization\n",
    "        resultNames = ('SourceDet1', 'SourceDet2', 'SourceDet3', 'SourceDet4', 'energy',\n",
    "                   'zenith', 'azimuth', 'actAzimuth')\n",
    "        t2 = Table(resultDict, names=resultNames)\n",
    "        t2.write('resultTable2.txt', format='ascii.ecsv')\n",
    "        \n",
    "else: # for weird localization\n",
    "        t2 = Table.read('resultTable2.txt', format='ascii.ecsv')\n",
    "        # t2.write('resultTable.txt', format='ascii.ecsv')\n",
    "        t2.add_row([resultDict['SourceDet1'], resultDict['SourceDet2'], resultDict['SourceDet3'],\n",
    "                   resultDict['SourceDet4'], resultDict['energy'],\n",
    "                   resultDict['zenith'], resultDict['azimuth'], resultDict['actAzimuth']])\n",
    "        t2.write('resultTable2.txt', format='ascii.ecsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../../hitsFile.txt', 'rb')\n",
    "a= open('../../angleFile.txt', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "p = pickle.load(f)\n",
    "l =pickle.load(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[278, 222, 212, 289],\n",
       " [222, 212, 289, 268],\n",
       " [212, 289, 268, 295],\n",
       " [289, 268, 295, 241],\n",
       " [268, 295, 241, 197],\n",
       " [295, 241, 197, 204],\n",
       " [241, 197, 204, 262],\n",
       " [197, 204, 262, 296],\n",
       " [204, 262, 296, 238],\n",
       " [262, 296, 238, 271],\n",
       " [296, 238, 271, 219],\n",
       " [238, 271, 219, 205],\n",
       " [271, 219, 205, 305]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p\n",
    "# ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 120.0, 240.0, 360.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
